# Exam OCR & Grading Pipeline

SystÃ¨me complet d'extraction de texte Ã  partir d'examens scannÃ©s et notation automatique avec LLM open source via API.

## ğŸ“‹ FonctionnalitÃ©s

- **OCR Handwritten** : Extraction de texte manuscrit Ã  partir d'images (franÃ§ais/anglais)
- **Segmentation Q/A** : SÃ©paration automatique questions/rÃ©ponses
- **Notation LLM Open Source** : Ã‰valuation avec modÃ¨les open source (Mistral, Llama-2, etc.) via API
- **Scores sur 20** : Notation sur l'Ã©chelle europÃ©enne (0-20)
- **Rapports dÃ©taillÃ©s** : Scores, feedback, recommandations d'amÃ©lioration
- **Traitement par lot** : Traite automatiquement tous les examens de `data/`

## ğŸ—‚ï¸ Structure

```
projet asma/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ GenAI/          # MatiÃ¨re 1
â”‚   â”‚   â”œâ”€â”€ copie1/     # Examen Ã©tudiant 1
â”‚   â”‚   â”œâ”€â”€ copie2/     # Examen Ã©tudiant 2
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ MLOps/          # MatiÃ¨re 2
â”‚       â”œâ”€â”€ copie1/
â”‚       â”œâ”€â”€ copie2/
â”‚       â””â”€â”€ ...
â”œâ”€â”€ results/            # RÃ©sultats (crÃ©Ã© automatiquement)
â”œâ”€â”€ ocr_pipeline.py     # Module OCR
â”œâ”€â”€ qa_extractor.py     # Segmentation Q/A
â”œâ”€â”€ grader.py           # Notation avec LLM
â”œâ”€â”€ batch_process_exams.py  # Script principal
â””â”€â”€ requirements.txt
```

## ğŸ“¦ Installation

### 1. DÃ©pendances Python

```bash
pip install -r requirements.txt
```

**GPU recommandÃ©** : Si vous avez NVIDIA (CUDA), TorchVision utilisera GPU pour accÃ©lÃ©rer l'OCR (~10x).

### 2. Configuration API LLM Open Source

Le systÃ¨me utilise des modÃ¨les LLM open source via API (Hugging Face par dÃ©faut).

**Ã‰tape 1 : Obtenir une clÃ© API**

Choisissez un service :
- **Hugging Face** (recommandÃ©) : https://huggingface.co/settings/tokens
- **Together AI** : https://api.together.xyz/
- **Replicate** : https://replicate.com/
- **Ou utilisez votre propre serveur local**

**Ã‰tape 2 : Configurer la clÃ©**

Option A - Variable d'environnement (Windows PowerShell):
```powershell
$env:LLM_API_KEY = "your-api-key-here"
```

Option B - Variable d'environnement (Mac/Linux):
```bash
export LLM_API_KEY="your-api-key-here"
```

Option C - Fichier `.env` (Ã  la racine du projet):
```
LLM_API_KEY=your-api-key-here
```

Option D - En ligne de commande:
```bash
python batch_process_exams.py --api-key "your-api-key-here"
```

**Voir [LLM_SETUP.md](LLM_SETUP.md) pour le guide complet de configuration.**

## ğŸš€ Utilisation

### Traitement complet

```bash
python batch_process_exams.py
```

**Options** :
- `--data data` : Chemin vers le dossier data/ (dÃ©faut)
- `--ocr-model french` : ModÃ¨le OCR (`french`, `english`, `french_printed`)
- `--api-key your-key` : ClÃ© API (ou utilise `LLM_API_KEY` env var)
- `--api-endpoint url` : URL de l'API (dÃ©faut: Hugging Face)
- `--model-name name` : Nom du modÃ¨le (dÃ©faut: Mistral-7B)
- `--skip-ocr` : Passe l'OCR si dÃ©jÃ  traitÃ©

### Exemples

```bash
# Configuration minimale (utilise env var LLM_API_KEY)
export LLM_API_KEY="hf_your-hugging-face-key"
python batch_process_exams.py

# Avec clÃ© en ligne de commande
python batch_process_exams.py --api-key "hf_your-key"

# Avec modÃ¨le Llama-2
python batch_process_exams.py --model-name "meta-llama/Llama-2-7b-chat-hf"

# Avec endpoint personnalisÃ© (serveur local)
python batch_process_exams.py \
  --api-endpoint "http://localhost:8000/api/generate" \
  --model-name "votre-modele"

# Sans clÃ© en ligne de commande (utilise env var)
export LLM_API_KEY="your-key"
python batch_process_exams.py
```

## ğŸ“Š RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans `results/YYYYMMDD_HHMMSS/`:

```
results/20240115_143022/
â”œâ”€â”€ summary.txt           # RÃ©sumÃ© global
â”œâ”€â”€ summary.json
â”œâ”€â”€ GenAI/
â”‚   â””â”€â”€ copie1/
â”‚       â”œâ”€â”€ 01_ocr_raw.txt       # Texte extrait
â”‚       â”œâ”€â”€ 02_questions_answers.txt  # Q/A formatÃ©es
â”‚       â”œâ”€â”€ 03_grade.json        # Note et feedback JSON
â”‚       â””â”€â”€ 04_report.txt        # Rapport lisible
â”‚   â””â”€â”€ copie2/
â”‚       â””â”€â”€ ...
â””â”€â”€ MLOps/
    â””â”€â”€ ...
```

### Contenu des fichiers

- **01_ocr_raw.txt** : Texte brut du OCR
- **02_questions_answers.txt** : Questions et rÃ©ponses numÃ©rotÃ©es
- **03_grade.json** : 
  ```json
  {
    "score": 15.5,
    "grade_letter": "B",
    "strengths": ["Bonne comprÃ©hension conceptuelle", ...],
    "weaknesses": ["Manque de dÃ©tails", ...],
    "feedback": "Analyse gÃ©nÃ©rale",
    "improvements": ["Approfondir X", ...]
  }
  ```
- **04_report.txt** : Rapport formatÃ© pour l'Ã©tudiant

## ğŸ¤– ModÃ¨les disponibles

### OCR
- `french` : Handwriting franÃ§ais (recommandÃ©)
- `english` : Handwriting anglais
- `french_printed` : Texte imprimÃ© franÃ§ais

### LLM Open Source

| ModÃ¨le | Vitesse | QualitÃ© | Notes |
|--------|---------|---------|-------|
| **Mistral-7B** | âš¡âš¡âš¡ | â­â­â­â­ | Excellent - recommandÃ© |
| **Llama-2-7B** | âš¡âš¡ | â­â­â­ | Bon |
| **Qwen-7B** | âš¡âš¡âš¡ | â­â­â­â­ | TrÃ¨s bon |
| **OpenHermes-2.5** | âš¡âš¡ | â­â­â­â­ | Excellent |
| **Llama-2-13B** | âš¡ | â­â­â­â­ | Haute qualitÃ© |
| **Llama-2-70B** | ğŸ¢ | â­â­â­â­â­ | Meilleure qualitÃ© |

**Services recommandÃ©s:**
- **Hugging Face** (gratuit) : https://huggingface.co/
- **Together AI** (gratuit au dÃ©part) : https://www.together.ai/
- **Replicate** (gratuit + payant) : https://replicate.com/

## âš™ï¸ Configuration avancÃ©e

Pour modifier les paramÃ¨tres d'OCR, Ã©ditez `batch_process_exams.py`:

```python
config = OCRConfig(
    model_type=ModelType.FRENCH,
    remove_watermark=True,           # CamScanner logos
    remove_blue_lines=True,          # Papier rÃ©glÃ©
    max_line_height=70,              # Adapter si lignes fusionnent
    num_beams=6,                     # 8-10 pour plus de prÃ©cision (plus lent)
)
```

## ğŸ› Troubleshooting

### ClÃ© API invalide
```
âŒ OPENAI_API_KEY not found
```
â†’ VÃ©rifiez votre clÃ© API dans les variables d'env
â†’ CrÃ©ez un fichier `.env` avec vos clÃ©s

### Erreur de connexion API
â†’ VÃ©rifiez votre connexion Internet
â†’ VÃ©rifiez que le provider est accessible

### OCR donne du charabia
â†’ VÃ©rifiez que les images sont claires et bien scannÃ©es
â†’ Essayez `--ocr-model french_printed` si texte imprimÃ©

### LLM lent
â†’ Utilisez un modÃ¨le plus lÃ©ger (gpt-3.5 au lieu de gpt-4)
â†’ Ou `--skip-ocr` pour passer la notation

## ğŸ“ Exemple de workflow

1. **Scannez vos examens** : CamScanner ou photographiez chaque page
2. **Organisez** : 
   ```
   data/GenAI/copie1/page1.jpg
   data/GenAI/copie1/page2.jpg
   data/GenAI/copie2/page1.jpg
   ...
   ```
3. **Lancez le script** :
   ```bash
   python batch_process_exams.py
   ```
4. **Consultez les rÃ©sultats** dans le dossier `results/`

## ğŸ” Format des noms de fichiers

Les fichiers images doivent Ãªtre nommÃ©s simplement :
- AcceptÃ©s : `page1.jpg`, `1.png`, `answer.jpg`
- RejetÃ©s : aucun fichier image = Ã©tudiant ignorÃ©

## ğŸ“§ Fichiers de sortie JSON

Pour intÃ©gration avec d'autres systÃ¨mes :

```python
import json

# Lire le rÃ©sumÃ©
with open("results/20240115_143022/summary.json") as f:
    summary = json.load(f)
    for student_id, result in summary["by_subject"]["GenAI"]["students"].items():
        print(f"{student_id}: {result['grade']}/20")

# Lire la note dÃ©taillÃ©e
with open("results/20240115_143022/GenAI/copie1/03_grade.json") as f:
    grade = json.load(f)
    print(f"Score: {grade['score']}/20")
    print(f"Points forts: {grade['strengths']}")
```

## ğŸ› ï¸ Personnalisation

### Changer le modÃ¨le OCR

Ã‰ditez `batch_process_exams.py`, ligne ~45:

```python
OCRConfig(
    model_type=ModelType.ENGLISH,  # â† ENGLISH, FRENCH, ou FRENCH_PRINTED
)
```

### Ajouter de nouveaux modÃ¨les

Modifiez `ocr_pipeline.py`, classe `TrOCREngine`:

```python
MODEL_CONFIGS = {
    ModelType.CUSTOM: {
        "processor": "microsoft/trocr-large-handwritten",
        "model": "votre_modele_huggingface",
    }
}
```

### Personnaliser la notation

Modifiez le prompt dans `grader.py`, mÃ©thode `_build_prompt()`.

## ğŸ“– RÃ©fÃ©rences

- **TrOCR** (Handwriting recognition) : https://huggingface.co/microsoft/trocr-large-handwritten
- **Ollama** (Local LLM) : https://ollama.ai
- **OpenCV** (Image processing) : https://docs.opencv.org

## ğŸ“„ Licence

Libre d'utilisation pour fins Ã©ducatives.

## ğŸ¤ Support

Pour des problÃ¨mes ou amÃ©liorations, contactez-moi ou consultez les logs dÃ©taillÃ©s.
